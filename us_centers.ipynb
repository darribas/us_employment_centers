{
 "metadata": {
  "name": "",
  "signature": "sha256:4ed034cc11ed892ff96da13d260906d7d60e8a3f78599b49b7ed17ab6b7a182e"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "*\"The Validity of the Monocentric City Model in a Polycentric Age: US Metropolitan Areas in 1990, 2000 and 2010\"*"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "[Dani Arribas-Bel](http://darribas.org) and Fernando Sanz-Gracia"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This document presents the code and steps neccesary to reproduce the results in the paper *\"The Validity of the Monocentric City Model in a Polycentric Age: US Metropolitan Areas in 1990, 2000 and 2010\"*, by Dani Arribas-Bel and Fernando Sanz-Gracia, forthcoming in the journal Urban Geography. If you want to cite the paper or use any of the code and/or results in it, please use the following citation:"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "@article{arribasbel_sanzgracia_centersUS,\n",
      "\tauthor = \"Arribas-Bel, Daniel and Sanz-Gracia, Fernando\",\n",
      "\tjournal = \"Urban Geography\",\n",
      "\ttitle = \"{The Validity of the Monocentric City Model in a Polycentric Age: \n",
      "            US Metropolitan Areas in 1990, 2000 and 2010}\",\n",
      "\tyear = \"2014\",\n",
      "\tvolume = \"\",\n",
      "    pages = {}\n",
      "}"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Access and software requirements"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import pandas as pd\n",
      "import employment_centers_tools as tools"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Employment data for 1990 and 2000 comes from the [\u201cCensus 2000 Special Tabulation Product 64\u201d](http://www.census.gov/mp/www/cat/decennial_census_2000/census_2000_special_tabulation_census_tract_of_work_by_census_tract_of_residence_stp_64.html) (`stp64`), which offers tract- to-tract commuting flows for the whole country. We consider only tracts within boundaries of the MSAs studied and sum over inflows to obtain employment numbers at the tract level. For 2010, there is no `stp64` so we use the [Census Transportation Planning Products](http://ctpp.transportation.org/Pages/5-Year-Info.aspx) (CTPP) 5-year small area data, which is based on ACS 2006-2010 Census Data and provides employment counts at the tract level for 2010.\n",
      "\n",
      "Since it is not clear to the authors whether it is legal to redistribute original Census data (particularly when the `stp64` is not available as a free download), **the raw dataset used for this paper is not included**. However, in order to illustrate how the process was carried out, below we show the structure of the data and how that is entered into the code to identify employment centers. This should allow users who have accessed the original data from the Census to replicate our results. We do provide the output of the center identification in the form of shapefiles (one per MSA per year). These can be found in the repository where this notebook and other code is hosted."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We store employment data in `csv` files, using a separate one for each MSA for each year. The raw format of these files is as follows, where the top of the file for MSA 10180 in 1990 is shown:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!head /Users/dani/AAA/LargeData/T-CentersData/attributes/3-empDen/empDen1990/10180.csv"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "gisjoin2,emp,area,dens,densEB\r\n",
        "48044100102,2855.0,45088315.8862,6.33201738385e-05,6.32174061116e-05\r\n",
        "48044100105,357.0,16138974.527,2.212036455e-05,2.20337682175e-05\r\n",
        "48044100104,272.0,18017057.8625,1.5096804488e-05,1.56769988243e-05\r\n",
        "48044100107,565.0,18156353.5203,3.11185833305e-05,3.18837079257e-05\r\n",
        "48044100108,1484.0,25713732.5898,5.77123525267e-05,5.73154004704e-05\r\n",
        "48044100106,342.0,25402742.4933,1.34631132875e-05,1.35600665231e-05\r\n",
        "48044100110,1095.0,12176093.1624,8.99303237414e-05,8.84590480255e-05\r\n",
        "48044100112,1339.0,20690727.6527,6.47149787323e-05,6.86296980824e-05\r\n",
        "48044100113,2364.0,30324316.5093,7.79572393421e-05,7.73806762075e-05\r\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "These files can be loaded and combined for 1990 in one `DataFrame` with the following code:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "empF90 = '/Users/dani/AAA/LargeData/T-CentersData/attributes/3-empDen/empDen1990/'\n",
      "emp90 = pd.concat([tools.load_msa_data(empF90+f, y90=True) for f in os.listdir(empF90)])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "emp90.info()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<class 'pandas.core.frame.DataFrame'>\n",
        "Index: 54994 entries, G48044100102 to G04001900049\n",
        "Data columns (total 3 columns):\n",
        "emp           54994 non-null float64\n",
        "Shape_area    54994 non-null float64\n",
        "msa           54994 non-null object\n",
        "dtypes: float64(2), object(1)"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "emp90.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>emp</th>\n",
        "      <th>Shape_area</th>\n",
        "      <th>msa</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>gisjoin2</th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>G48044100102</th>\n",
        "      <td> 2855</td>\n",
        "      <td> 4.188840</td>\n",
        "      <td> m10180</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>G48044100105</th>\n",
        "      <td>  357</td>\n",
        "      <td> 1.499359</td>\n",
        "      <td> m10180</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>G48044100104</th>\n",
        "      <td>  272</td>\n",
        "      <td> 1.673839</td>\n",
        "      <td> m10180</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>G48044100107</th>\n",
        "      <td>  565</td>\n",
        "      <td> 1.686780</td>\n",
        "      <td> m10180</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>G48044100108</th>\n",
        "      <td> 1484</td>\n",
        "      <td> 2.388883</td>\n",
        "      <td> m10180</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "               emp  Shape_area     msa\n",
        "gisjoin2                              \n",
        "G48044100102  2855    4.188840  m10180\n",
        "G48044100105   357    1.499359  m10180\n",
        "G48044100104   272    1.673839  m10180\n",
        "G48044100107   565    1.686780  m10180\n",
        "G48044100108  1484    2.388883  m10180"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Similar steps can be taken for 2000:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "empF00 = '/Users/dani/AAA/LargeData/T-CentersData/attributes/3-empDen/empDen2000/'\n",
      "emp00 = pd.concat([tools.load_msa_data(empF00+f) for f in os.listdir(empF00)])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Steps for 2010 are slightly different as the data are collected from a different source. We begin with a `csv` that looks as follows:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!head /Users/dani/AAA/LargeData/ctpp/data2010/tractPOW_all.csv"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "head: /Users/dani/AAA/LargeData/ctpp/data2010/tractPOW_all.csv: No such file or directory\r\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "emp10_link = '/Users/dani/AAA/LargeData/ctpp/data2010/tractPOW_all.csv'\n",
      "shp_link = '/Users/dani/AAA/LargeData/nhgis/shapeFiles/nhgis0019_shapefile_tl2010_us_tract_2010/US_tract_2010.shp'\n",
      "cty2msa = pd.read_csv('cty2msa.csv', names=['cty', 'msa'], index_col=0, squeeze=True)\n",
      "shpW_out = '/Users/dani/AAA/LargeData/nhgis/shapeFiles/nhgis0019_shapefile_tl2010_us_tract_2010/msa_shapes_ws/'\n",
      "emp10 = pd.read_csv(emp10_link)[['GISJOIN', 'emp', 'Shape_area']]\n",
      "emp10['Shape_area'] = emp10['Shape_area'] * 0.000001 #Area in Km2\n",
      "emp10['msa'] = emp10['GISJOIN'].apply(lambda x: \\\n",
      "        msafy('c'+x[1:3]+x[4:7], cty2msa))\n",
      "emp10 = emp10.dropna() # Only tracts in MSA && w/ employment\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "IOError",
       "evalue": "File cty2msa.csv does not exist",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-23-297e59447a27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0memp10_link\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/Users/dani/AAA/LargeData/ctpp/data2010/tractPOW_all.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mshp_link\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/Users/dani/AAA/LargeData/nhgis/shapeFiles/nhgis0019_shapefile_tl2010_us_tract_2010/US_tract_2010.shp'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcty2msa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cty2msa.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cty'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'msa'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msqueeze\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mshpW_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/Users/dani/AAA/LargeData/nhgis/shapeFiles/nhgis0019_shapefile_tl2010_us_tract_2010/msa_shapes_ws/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0memp10\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memp10_link\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'GISJOIN'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'emp'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Shape_area'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/dani/anaconda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, dialect, compression, doublequote, escapechar, quotechar, quoting, skipinitialspace, lineterminator, header, index_col, names, prefix, skiprows, skipfooter, skip_footer, na_values, na_fvalues, true_values, false_values, delimiter, converters, dtype, usecols, engine, delim_whitespace, as_recarray, na_filter, compact_ints, use_unsigned, low_memory, buffer_lines, warn_bad_lines, error_bad_lines, keep_default_na, thousands, comment, decimal, parse_dates, keep_date_col, dayfirst, date_parser, memory_map, nrows, iterator, chunksize, verbose, encoding, squeeze, mangle_dupe_cols, tupleize_cols, infer_datetime_format)\u001b[0m\n\u001b[1;32m    441\u001b[0m                     infer_datetime_format=infer_datetime_format)\n\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/dani/anaconda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnrows\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/dani/anaconda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    531\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_options_with_defaults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/dani/anaconda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m    668\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 670\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    671\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/dani/anaconda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1030\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1032\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1033\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/dani/anaconda/lib/python2.7/site-packages/pandas/parser.so\u001b[0m in \u001b[0;36mpandas.parser.TextReader.__cinit__ (pandas/parser.c:3213)\u001b[0;34m()\u001b[0m\n",
        "\u001b[0;32m/Users/dani/anaconda/lib/python2.7/site-packages/pandas/parser.so\u001b[0m in \u001b[0;36mpandas.parser.TextReader._setup_parser_source (pandas/parser.c:5595)\u001b[0;34m()\u001b[0m\n",
        "\u001b[0;31mIOError\u001b[0m: File cty2msa.csv does not exist"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Once all the data are loaded, it is very straightforward to replicate Table 1 in the paper:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "table = pd.DataFrame()\n",
      "for year, emp in [(1990, emp90), (2000, emp00)]:\n",
      "    minTpMSA = emp.groupby('msa').count()['emp'].min()\n",
      "    maxTpMSA = emp.groupby('msa').count()['emp'].max()\n",
      "    meanTpMSA = emp.groupby('msa').count()['emp'].mean()\n",
      "    summary = pd.Series({'N. MSAs': len(emp['msa'].unique()), \\\n",
      "                          'N. Tracts': len(emp), \\\n",
      "                          'Min. N. Tracts/MSA': minTpMSA, \\\n",
      "                          'Max. N. Tracts/MSA': maxTpMSA, \\\n",
      "                          'Average. N. Tracts/MSA': meanTpMSA})\n",
      "    table[year] = summary\n",
      "table.reindex(['N. MSAs', 'N. Tracts', 'Min. N. Tracts/MSA', \\\n",
      "               'Max. N. Tracts/MSA', 'Average. N. Tracts/MSA'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>1990</th>\n",
        "      <th>2000</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>N. MSAs</th>\n",
        "      <td>   359.00000</td>\n",
        "      <td>   359.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>N. Tracts</th>\n",
        "      <td> 54994.00000</td>\n",
        "      <td> 52329.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Min. N. Tracts/MSA</th>\n",
        "      <td>    17.00000</td>\n",
        "      <td>    10.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Max. N. Tracts/MSA</th>\n",
        "      <td>  4565.00000</td>\n",
        "      <td>  4493.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Average. N. Tracts/MSA</th>\n",
        "      <td>   153.18663</td>\n",
        "      <td>   145.763231</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 36,
       "text": [
        "                               1990          2000\n",
        "N. MSAs                   359.00000    359.000000\n",
        "N. Tracts               54994.00000  52329.000000\n",
        "Min. N. Tracts/MSA         17.00000     10.000000\n",
        "Max. N. Tracts/MSA       4565.00000   4493.000000\n",
        "Average. N. Tracts/MSA    153.18663    145.763231"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Center identification"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We use the data we loaded originally and combine them with geographical data to derive spatial relationships (these are needed to run the main identification algorithm). We use shapefiles of the tracts for each year downloaded from [NHGIS](http://nhgis.org) and projected to state plane so areas can be calculated (not included in the repository either for similar redistribution reasons as with employment data).\n",
      "\n",
      "Since not all data is shipped in the repository, the code below will only run if you provide it separately. This implies you need to place the MSA shapefiles for each year in the `cent_outYY` folder (replace `YY` by the year). Once you run the code below, shapefiles and `.gal` files will be created in the same directory. These should be equivalent to the shapefiles with the identified centers provided in the repository under the `json` files `centerYYYY`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import multiprocessing as mp\n",
      "#pool = mp.Pool(mp.cpu_count())\n",
      "seed = np.random.seed(1234)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For 1990, this would identify the centers (make sure to modify `cent_in90` and `cent_out90` to fit your setup):"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "reload(tools)\n",
      "cent_in90 = '/Users/dani/AAA/LargeData/T-CentersData/shapes/msaTracts1990polygonsSP/'\n",
      "cent_out90 = '/Users/dani/Desktop/test90/'\n",
      "\n",
      "emp90['dens_raw'] = (emp90['emp'] * 1.) / emp90['Shape_area']\n",
      "emp90['GISJOIN'] = emp90.index\n",
      "pars = [(emp90[emp90['msa']==msa], cent_in90+msa[1:]+'.shp', cent_out90) \\\n",
      "        for msa in emp90['msa'].unique()]\n",
      "\n",
      "_ = tools.act_on_msa(pars[0], permutations=9)\n",
      "#out = map(tools.act_on_msa, pars[:2])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "KeyError",
       "evalue": "'G48039909501'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-6-db6c8857ebdc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mpars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memp90\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0memp90\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'msa'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mmsa\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcent_in90\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mmsa\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.shp'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcent_out90\u001b[0m\u001b[0;34m)\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmsa\u001b[0m \u001b[0;32min\u001b[0m \u001b[0memp90\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'msa'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact_on_msa\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpermutations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;31m#out = map(tools.act_on_msa, pars[:2])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/dani/AAA/Documents/phd/T-Centers/site/employment_centers_tools.py\u001b[0m in \u001b[0;36mact_on_msa\u001b[0;34m(empShpOut_paths, thr, permutations)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;31m# get EB rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m     eb = ps.esda.smoothing.Spatial_Empirical_Bayes(\\\n\u001b[0;32m--> 215\u001b[0;31m             emp['emp'].values, emp['Shape_area'].values, w)\n\u001b[0m\u001b[1;32m    216\u001b[0m     \u001b[0memp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dens_eb'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[0memp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dens_eb'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0memp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dens_eb'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Avoid sliver problem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/dani/code/pysal_darribas/pysal/esda/smoothing.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, e, b, w)\u001b[0m\n\u001b[1;32m    707\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid_order_set\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"w id_order must be set to align with the order of e an b\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m         \u001b[0mr_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSpatial_Rate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    710\u001b[0m         \u001b[0mrate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1.0\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m         \u001b[0mr_var_left\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/dani/code/pysal_darribas/pysal/esda/smoothing.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, e, b, w)\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'b'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 782\u001b[0;31m             \u001b[0mw_e\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    783\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mw_e\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mw_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    784\u001b[0m             \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'o'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/dani/code/pysal_darribas/pysal/weights/spatial_lag.pyc\u001b[0m in \u001b[0;36mlag_spatial\u001b[0;34m(w, y)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \"\"\"\n\u001b[0;32m---> 84\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;32m/Users/dani/code/pysal_darribas/pysal/weights/weights.pyc\u001b[0m in \u001b[0;36msparse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \"\"\"\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'sparse'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sparse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sparse'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/dani/code/pysal_darribas/pysal/weights/weights.pyc\u001b[0m in \u001b[0;36m_build_sparse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid2i\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcard\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0mcol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneigh_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m         \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0mcol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mKeyError\u001b[0m: 'G48039909501'"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For 2000, this would identify the centers (make sure to modify `cent_in00` and `cent_out00` to fit your setup):"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cent_in00 = '/Users/dani/AAA/LargeData/T-CentersData/shapes/msaTracts2000polygonsSP/'\n",
      "cent_out00 = '/Users/dani/Desktop/test00/'\n",
      "\n",
      "emp00['dens_raw'] = (emp00['emp'] * 1.) / emp00['Shape_area']\n",
      "emp00['GISJOIN'] = emp00.index\n",
      "pars = [(emp00[emp00['msa']==msa], cent_in00+msa[1:]+'.shp', cent_out00) \\\n",
      "        for msa in emp00['msa'].unique()]\n",
      "\n",
      "_ = tools.act_on_msa(pars[0], permutations=9)\n",
      "#out = map(tools.act_on_msa, pars[:2])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For 2010, this would identify the centers (make sure to modify `cent_in10` and `cent_out10` to fit your setup). Note that in this case, the way the shapefile is passed is slightly different because we are using 2010 data that we have sourced differently."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cent_out10 = '/Users/dani/Desktop/test10/'\n",
      "shp_link = '/Users/dani/AAA/LargeData/nhgis/shapeFiles/nhgis0019_shapefile_tl2010_us_tract_2010/US_tract_2010.shp'\n",
      "\n",
      "emp10['dens_raw'] = (emp10['emp'] * 1.) / emp10['Shape_area']\n",
      "emp10['GISJOIN'] = emp10.index\n",
      "pars = [(emp10[emp10['msa']==msa], shp_link, cent_out10) \\\n",
      "        for msa in emp10['msa'].unique()]\n",
      "\n",
      "_ = tools.act_on_msa(pars[0], permutations=9)\n",
      "#out = map(tools.act_on_msa, pars[:2])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Spatial analysis of polycentricity"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "Maps 1-2"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "City Characterization"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "Tables 5-8"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}